{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import BallTree\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import cross_val_predict, KFold\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "def get_nearest_neighbors(gdf, k_neighbors=5):\n",
    "\n",
    "    src_points = [(x,y) for x,y in zip(gdf.geometry.x , gdf.geometry.y)]\n",
    "    candidates =  [(x,y) for x,y in zip(gdf.geometry.x , gdf.geometry.y)]\n",
    "\n",
    "    # Create tree from the candidate points\n",
    "    tree = BallTree(candidates, leaf_size=15, metric='euclidean')\n",
    "\n",
    "    # Find closest points and distances\n",
    "    distances, indices = tree.query(src_points, k=k_neighbors+1)\n",
    "\n",
    "    # Transpose to get distances and indices into arrays\n",
    "    distances = distances.transpose()\n",
    "    indices = indices.transpose()\n",
    "\n",
    "    closest_gdfs = []\n",
    "    for k in np.arange(k_neighbors):\n",
    "        gdf_new = gdf.iloc[indices[k+1]].reset_index()\n",
    "        del gdf_new['index']\n",
    "        gdf_new = gdf_new.add_suffix(f'_{k+1}')\n",
    "        closest_gdfs.append(gdf_new)\n",
    "        \n",
    "    closest_gdfs.insert(0,gdf)    \n",
    "    gdf_final = pd.concat(closest_gdfs,axis=1)\n",
    "\n",
    "    return gdf_final\n",
    "\n",
    "def rfsi(gdf, k_neighbors=5, vname = '', ntrees = 150, seed = None, folds = 5):\n",
    "    # Definimos el nombre del target y el valor de k para k-nearest neighbors\n",
    "    target = vname\n",
    "    \n",
    "    # Creamos el modelo de Random Forest\n",
    "    random_forest_model = RandomForestRegressor(n_estimators=ntrees, random_state=seed)\n",
    "    \n",
    "    if isinstance(k_neighbors, list):\n",
    "        xv = pd.DataFrame(columns=['knn','rmse'])\n",
    "        for j in k_neighbors:\n",
    "            knn = j\n",
    "\n",
    "            # Obtenemos los knn vecinos más cercanos\n",
    "            gdf_nn = get_nearest_neighbors(gdf=gdf,k_neighbors=knn)\n",
    "            # Generamos automáticamente el nombre de las características basadas en el nombre del target y el valor de k\n",
    "            features = [f'{target}_{i}' for i in range(1, knn + 1)]\n",
    "            X = gdf_nn[features]\n",
    "            y = gdf_nn[target]\n",
    "\n",
    "            # Define los pliegues para la validación cruzada\n",
    "            kf = KFold(n_splits=folds, shuffle=True, random_state=seed)\n",
    "\n",
    "            # Realiza la validación cruzada y obtiene las predicciones y los valores reales\n",
    "            predictions = cross_val_predict(random_forest_model, X, y, cv=kf)\n",
    "\n",
    "            # Crear un DataFrame con las columnas \"Observado\" y \"Predicho\"\n",
    "            residuals = pd.DataFrame({'observado': y, 'predicho': predictions})\n",
    "\n",
    "            # Calcular el RMSE utilizando los valores observados y predichos en el DataFrame\n",
    "            rmse = np.sqrt(mean_squared_error(residuals['observado'], residuals['predicho']))\n",
    "\n",
    "            #Registrar el valor de rmse\n",
    "            #xv = pd.concat([xv, pd.DataFrame({'knn': [knn], 'rmse': [rmse]})], ignore_index=True)\n",
    "            xv.loc[len(xv)] = [knn, rmse]\n",
    "        \n",
    "        #Filtrar el menor rmse\n",
    "        min_rmse = xv.loc[xv['rmse'].idxmin()]\n",
    "\n",
    "        #Obtener el nuemro de vecinos optimo\n",
    "        knn = min_rmse['knn']\n",
    "        rmse = min_rmse['rmse']\n",
    "        print(\"Numero vecinos optimo: \", knn, \" - rmse: \", round(rmse,3))\n",
    "    elif isinstance(k_neighbors, int):\n",
    "        knn = k_neighbors\n",
    "    else:\n",
    "        return \"Tipo de dato no soportado para k_neighbors\"\n",
    "    # Obtenemos los knn vecinos más cercanos\n",
    "    gdf_nn = get_nearest_neighbors(gdf=gdf,k_neighbors=knn)\n",
    "\n",
    "    # Generamos automáticamente el nombre de las características basadas en el nombre del target y el valor de k\n",
    "    features = [f'{target}_{i}' for i in range(1, knn + 1)]\n",
    "    X = gdf_nn[features]\n",
    "    y = gdf_nn[target]\n",
    "\n",
    "    # Entrena el modelo utilizando todos los datos\n",
    "    random_forest_model.fit(X, y)\n",
    "\n",
    "    # Retorna el modelo entrenado\n",
    "    return random_forest_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE:  6.816\n"
     ]
    }
   ],
   "source": [
    "import geopandas as gpd\n",
    "obs = gpd.read_file(filename=\"Data/ECa.gpkg\",layer=\"EC_field_01\")\n",
    "knn = 5\n",
    "model= rfsi(gdf=obs,k_neighbors=knn,vname='EC90',seed=701408733)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "obs = gpd.read_file(filename=\"Data/ECa.gpkg\",layer=\"EC_field_01\")\n",
    "knn = [5,10,15,20,25]\n",
    "model = rfsi(gdf=obs,k_neighbors=knn,vname='EC90',seed=701408733)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
